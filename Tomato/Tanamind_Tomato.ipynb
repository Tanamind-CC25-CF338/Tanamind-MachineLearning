{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-z4QGlO8DC1"
   },
   "source": [
    "## Import Semua Packages/Library yang Digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVYwaObI8DC1"
   },
   "outputs": [],
   "source": [
    "# Library yang sering digunakan\n",
    "import os, shutil\n",
    "import zipfile\n",
    "import random\n",
    "from random import sample\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm as tq # untuk menampilkna bar progres saat proses iterasi\n",
    "\n",
    "# Libraries untuk pemrosesan data gambar\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.exposure import adjust_gamma\n",
    "from skimage.util import random_noise\n",
    "\n",
    "# Libraries untuk pembangunan model\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, SeparableConv2D, MaxPooling2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Import the required library\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import seaborn as sns\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YV9YPDb6nPvg"
   },
   "outputs": [],
   "source": [
    "# Untuk menonaktifkan warinig yang mungkin muncul, seperti FutureWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dEMRESDnSjY",
    "outputId": "cef8ee6d-e0cf-445a-df9a-9d7e8a1d686b"
   },
   "outputs": [],
   "source": [
    "# Mencetak versi TensorFlow yang sedang digunakan\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "heZb6wrfm-eC",
    "outputId": "cadaa9ed-12cf-49bf-db5b-68ada3c019ff"
   },
   "outputs": [],
   "source": [
    "# Menggunakan Google Colab\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK4DvqfbYrN8"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHekw29KX4XQ"
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "wIcv1F9fX4XQ",
    "outputId": "1527acb1-6971-4647-8389-7fa83f34d357"
   },
   "outputs": [],
   "source": [
    "# Import module yang disediakan google colab untuk kebutuhan upload file\n",
    "\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nra2MIpmnhCx"
   },
   "outputs": [],
   "source": [
    "# Buat direktori jika belum ada\n",
    "\n",
    "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "\n",
    "# Pindahkan file ke direktori .kaggle\n",
    "\n",
    "shutil.move(\"kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
    "\n",
    "# Atur permission agar tidak terlalu terbuka\n",
    "\n",
    "os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYIpMWpcnnf4",
    "outputId": "30458144-db6e-435b-942f-fd6883f849d7"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download cookiefinder/tomato-disease-multiple-sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpPAI0H5MCaz",
    "outputId": "446319d5-6bd3-44a9-c698-6ddb9a364b7e"
   },
   "outputs": [],
   "source": [
    "!unzip tomato-disease-multiple-sources.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnnOWhjLoW-4"
   },
   "source": [
    "### Dataset Checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMPpAlZQodRZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2a0xr7wjpTBx"
   },
   "outputs": [],
   "source": [
    "# Direktori awal untuk train dan test\n",
    "train_dir = 'train'\n",
    "test_dir = 'valid'\n",
    "\n",
    "# Direktori baru untuk dataset gabungan\n",
    "combined_dir = \"Tomato-Disease/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-gPV_LMpjiJ"
   },
   "outputs": [],
   "source": [
    "# direktori baru untuk dataset gabungan\n",
    "os.makedirs(combined_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhdTpLBZp1xp"
   },
   "outputs": [],
   "source": [
    "# Daftar kelas penyakit daun non-parasit\n",
    "leaf_disease_class = [\n",
    "    \"Bacterial_spot\",\n",
    "    \"Early_blight\",\n",
    "    \"Late_blight\",\n",
    "    \"Leaf_Mold\",\n",
    "    \"Septoria_leaf_spot\",\n",
    "    \"Target_Spot\",\n",
    "    \"healthy\",\n",
    "    \"powdery_mildew\"\n",
    "]\n",
    "\n",
    "# Salin folder dari train_dir\n",
    "for category in os.listdir(train_dir):\n",
    "    if category in leaf_disease_class:\n",
    "        category_dir = os.path.join(train_dir, category)\n",
    "        if os.path.isdir(category_dir):\n",
    "            shutil.copytree(category_dir, os.path.join(combined_dir, category), dirs_exist_ok=True)\n",
    "\n",
    "# Salin folder dari test_dir\n",
    "for category in os.listdir(test_dir):\n",
    "    if category in leaf_disease_class:\n",
    "        category_dir = os.path.join(test_dir, category)\n",
    "        if os.path.isdir(category_dir):\n",
    "            shutil.copytree(category_dir, os.path.join(combined_dir, category), dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "6cI31O2JrCFh",
    "outputId": "656f529a-88d4-44e4-a997-093c51f138e2"
   },
   "outputs": [],
   "source": [
    "path = 'Tomato-Disease/dataset'\n",
    "rice_image = {}\n",
    "\n",
    "# Hanya ambil folder (class) yang valid\n",
    "for i in os.listdir(path):\n",
    "    class_path = os.path.join(path, i)\n",
    "    if os.path.isdir(class_path):\n",
    "        images = os.listdir(class_path)\n",
    "        rice_image[i] = images\n",
    "\n",
    "# menampilkan secara acak 5 gambar di bawah setiap kelas dari data\n",
    "path_sub = \"Tomato-Disease/dataset\"\n",
    "\n",
    "# menampilkan secarak acak 5 gambar di bawah setiap kelas dari data latih\n",
    "fig, axs = plt.subplots(len(rice_image.keys()), 5, figsize=(15, 15))\n",
    "\n",
    "for i, class_name in enumerate(rice_image.keys()):\n",
    "    images = rice_image[class_name]\n",
    "\n",
    "    if len(images) >= 5:\n",
    "        sampled_images = np.random.choice(images, 5, replace=False)\n",
    "    else:\n",
    "        print(f\"[WARNING] Kelas '{class_name}' hanya memiliki {len(images)} gambar. Menampilkan semua.\")\n",
    "        sampled_images = images + [''] * (5 - len(images))  # padding kosong agar tidak error\n",
    "\n",
    "    for j, image_name in enumerate(sampled_images):\n",
    "        ax = axs[i, j]\n",
    "        if image_name != '':\n",
    "            img_path = os.path.join(path, class_name, image_name)\n",
    "            img = Image.open(img_path)\n",
    "            ax.imshow(img)\n",
    "        ax.set(xlabel=class_name, xticks=[], yticks=[])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCtF1MUNyVC7"
   },
   "source": [
    "### Plot Distribusi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "lZoJtMPKyXP6",
    "outputId": "1ad303ea-4ae3-4108-f5bc-8bda750ecd14"
   },
   "outputs": [],
   "source": [
    "# path sumber\n",
    "tomato_path = 'Tomato-Disease/dataset'\n",
    "\n",
    "# daftar untuk menyimpan data untuk setiap nama file, path file, dan label dalam data\n",
    "file_name = []\n",
    "labels = []\n",
    "full_path=[]\n",
    "\n",
    "# mengambil file gamber, path file, dan label\n",
    "for path, subdirs, files in os.walk(tomato_path):\n",
    "  for name in files:\n",
    "    full_path.append(os.path.join(path, name))\n",
    "    labels.append(path.split('/')[-1])\n",
    "    file_name.append(name)\n",
    "\n",
    "distribution_train = pd.DataFrame({\"path\":full_path, 'file_name':file_name, 'labels':labels})\n",
    "\n",
    "# plot distribusi\n",
    "Label = distribution_train['labels']\n",
    "plt.figure(figsize = (6, 6))\n",
    "sns.set_style(\"darkgrid\")\n",
    "plot_data = sns.countplot(Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFgLyQPHX98s"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ON6tjCvZzzEi"
   },
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CL6rkXQA0BRq"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import numpy as np\n",
    "# import random\n",
    "# from skimage.transform import resize\n",
    "# from skimage.filters import gaussian\n",
    "# from skimage import img_as_float\n",
    "\n",
    "# # Membuat fungsi untuk melakukan rotasi berlawanan arah jarum jam\n",
    "# def anticlockwise_rotation(img):\n",
    "#     img = tf.image.resize(img, (224, 224))\n",
    "#     img = tf.image.rot90(img, k=random.randint(1, 4))  # Rotasi 90, 180, atau 270 derajat secara acak\n",
    "#     return img\n",
    "\n",
    "# # Membuat fungsi untuk melakukan rotasi searah jarum jam\n",
    "# def clockwise_rotation(img):\n",
    "#     img = tf.image.resize(img, (224, 224))\n",
    "#     img = tf.image.rot90(img, k=random.randint(1, 4))  # Rotasi 90, 180, atau 270 derajat secara acak\n",
    "#     return img\n",
    "\n",
    "# # Membuat fungsi untuk membalik gambar secara vertikal dari atas ke bawah\n",
    "# def flip_up_down(img):\n",
    "#     img = tf.image.resize(img, (224, 224))\n",
    "#     img = tf.image.flip_up_down(img)\n",
    "#     return img\n",
    "\n",
    "# # Membuat fungsi untuk memberikan efek peningkatan kecerahan pada gambar\n",
    "# def add_brightness(img):\n",
    "#     img = tf.image.resize(img, (224, 224))\n",
    "#     img = tf.image.adjust_brightness(img, delta=random.uniform(0.1, 0.5))  # Sesuaikan nilai delta sesuai kebutuhan\n",
    "#     return img\n",
    "\n",
    "# # Membuat fungsi untuk memberikan efek blur pada gambar\n",
    "# def blur_image(img):\n",
    "#     img = resize(img, (224, 224), preserve_range=True)\n",
    "#     img = img_as_float(img)  # pastikan nilainya antara 0 dan 1\n",
    "#     img = gaussian(img, sigma=1, channel_axis=-1)  # jika RGB, pastikan channel_axis benar\n",
    "#     return img\n",
    "\n",
    "# # Membuat fungsi untuk memberikan efek pergeseran acak pada gambar\n",
    "# def sheared(img):\n",
    "#     img = tf.image.resize(img, (224, 224))\n",
    "#     # Buat objek ImageDataGenerator dengan parameter shearing range\n",
    "#     datagen = ImageDataGenerator(shear_range=0.2)\n",
    "#     img = next(iter(datagen.flow(tf.expand_dims(img, 0))))[0]\n",
    "#     return img\n",
    "\n",
    "# # Membuat fungsi untuk melakukan pergeseran melengkung pada gambar\n",
    "# def warp_shift(img):\n",
    "#     img = tf.image.resize(img, (224, 224))\n",
    "#     # Buat objek ImageDataGenerator dengan parameter width_shift_range dan height_shift_range\n",
    "#     datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1)\n",
    "#     img = next(iter(datagen.flow(tf.expand_dims(img, 0))))[0]\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXtRaaR20FyC"
   },
   "outputs": [],
   "source": [
    "# transformations = {\n",
    "#     'rotate anticlockwise': anticlockwise_rotation,\n",
    "#     'rotate clockwise': clockwise_rotation,\n",
    "#     'warp shift': warp_shift,\n",
    "#     'blurring image': blur_image,\n",
    "#     'add brightness': add_brightness,\n",
    "#     'flip up down': flip_up_down,\n",
    "#     'shear image': sheared\n",
    "# }\n",
    "\n",
    "# images_path = \"tomato_disease/dataset/powdery_mildew\"  # Path for the original image\n",
    "# augmented_path = \"tomato_disease/dataset/powdery_mildew_augmented\"  # Path to put the augmented image\n",
    "# images = []  # To save images that have been preprocessed from the folder\n",
    "\n",
    "# # Baca nama gambar dari folder dan tambahkan path ke dalam array \"images\"\n",
    "# for im in os.listdir(images_path):\n",
    "#     images.append(os.path.join(images_path, im))\n",
    "\n",
    "# # Jumlah gambar yang akan ditambahkan dengan hasil transformasi augmentasi\n",
    "# images_to_generate = 2000\n",
    "# i = 1\n",
    "\n",
    "# while i <= images_to_generate:\n",
    "#     image = random.choice(images)\n",
    "#     try:\n",
    "#         original_image = io.imread(image)\n",
    "\n",
    "#         # Memeriksa apakah gambar memiliki dimensi yang valid (3 atau 4 dimensi)\n",
    "#         if original_image.ndim not in [3, 4]:\n",
    "#             raise ValueError('Invalid image dimensions')\n",
    "\n",
    "#         transformed_image = None\n",
    "#         n = 0  # Variabel untuk melakukan iterasi sampai jumlah transformasi yang akan diterapkan\n",
    "#         transformation_count = random.randint(1, len(transformations))  # Pilih jumlah transformasi acak yang akan diterapkan pada gambar\n",
    "\n",
    "#         while n <= transformation_count:\n",
    "#             key = random.choice(list(transformations))  # Secara acak memilih dan memanggil metode\n",
    "#             transformed_image = transformations[key](original_image)\n",
    "#             n = n + 1\n",
    "\n",
    "#         new_image_path = \"%s/augmented_image_%s.jpg\" % (augmented_path, i)\n",
    "#         transformed_image = img_as_ubyte(transformed_image)  # Mengonversi gambar ke format byte yang tidak ditandatangani, dengan nilai dalam [0, 255]\n",
    "#         cv2.imwrite(new_image_path, transformed_image)  # Simpan hasil transformasi augmentasi pada gambar ke path yang ditentukan\n",
    "#         i = i + 1\n",
    "#     except ValueError as e:\n",
    "#         print('Could not read or process the image', image, ':', e, 'hence skipping it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fEaUyM96YFb"
   },
   "outputs": [],
   "source": [
    "# # Define source path\n",
    "# tomato_path = \"tomato_disease/dataset/\"\n",
    "\n",
    "# # Create a list that stores data for each filenames, filepaths, and labels in the data\n",
    "# file_name = []\n",
    "# labels = []\n",
    "# full_path = []\n",
    "\n",
    "# # Get data image filenames, filepaths, labels one by one with looping, and store them as dataframe\n",
    "# for path, subdirs, files in os.walk(tomato_path):\n",
    "#     for name in files:\n",
    "#         full_path.append(os.path.join(path, name))\n",
    "#         labels.append(path.split('/')[-1])\n",
    "#         file_name.append(name)\n",
    "\n",
    "# distribution_train = pd.DataFrame({\"path\":full_path,'file_name':file_name,\"labels\":labels})\n",
    "\n",
    "# # Plot the distribution of images across the classes\n",
    "# Label = distribution_train['labels']\n",
    "# plt.figure(figsize = (6,6))\n",
    "# sns.set_style(\"darkgrid\")\n",
    "# plot_data = sns.countplot(Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ICO2-E0YxzD"
   },
   "source": [
    "#### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "8HJokQbxX98s",
    "outputId": "2e3d1949-cd50-4ae6-88fa-0e691115776f"
   },
   "outputs": [],
   "source": [
    "mypath = 'Tomato-Disease'\n",
    "\n",
    "file_name = []\n",
    "labels = []\n",
    "full_path = []\n",
    "for path, subdirs, files in os.walk(mypath):\n",
    "  for name in files:\n",
    "    full_path.append(os.path.join(path, name))\n",
    "    labels.append(path.split('/')[-1])\n",
    "    file_name.append(name)\n",
    "\n",
    "df = pd.DataFrame({'path':full_path, 'file_name':file_name, 'labels':labels})\n",
    "df.groupby(['labels']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vW3Ccf2IPN2P"
   },
   "outputs": [],
   "source": [
    "X = df['path']\n",
    "y = df['labels']\n",
    "\n",
    "# Step 1: Split jadi train (80%) dan temp (val+test 20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=300, stratify=y)\n",
    "\n",
    "# Step 2: Split temp jadi val dan test, masing-masing 50% dari temp (10% dari total awal)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=300, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGhocuPCPdJf"
   },
   "outputs": [],
   "source": [
    "# menyatukan ke dalam masing masing dataframe\n",
    "df_train = pd.DataFrame({'path':X_train, 'labels':y_train,'set':'train'})\n",
    "df_test = pd.DataFrame({'path':X_test, 'labels':y_test,'set':'test'})\n",
    "df_val = pd.DataFrame({'path':X_val, 'labels':y_val,'set':'val'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nHrQQexAP-d3",
    "outputId": "399bd09b-93dd-44c6-c987-6a0e6b86d45d"
   },
   "outputs": [],
   "source": [
    "# Print hasil diatas untuk melihat panjang size data training dan testing\n",
    "print('train_size',len(df_train))\n",
    "print('test_size',len(df_test))\n",
    "print('val_size',len(df_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7r7Fxj9gQFC3",
    "outputId": "7746a9d2-7a7d-4231-bbff-24d790231733"
   },
   "outputs": [],
   "source": [
    "# Gabungkan DataFrame df_tr dan df_te\n",
    "df_all = pd.concat([df_train, df_test, df_val], ignore_index=True)\n",
    "\n",
    "print('===================================================== \\n')\n",
    "print(df_all.groupby(['set', 'labels']).size(), '\\n')\n",
    "print('===================================================== \\n')\n",
    "\n",
    "# Cek sample data\n",
    "print(df_all.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEmHbwF8YZsB"
   },
   "outputs": [],
   "source": [
    "# memanggil dataset asli\n",
    "datasource_path = 'Tomato-Disease/dataset/'\n",
    "# membuat variabel dataset, tampat menampung data yng telah dilakukan split\n",
    "dataset_path = 'Dataset-Final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "5c97d65af1d140f78785e1b5eec4fd39",
      "b39aec058fb44e2c86793272957603c4",
      "f84f0cc0c8784e09b1fa5764b2a52108",
      "f436e244c2484bacaf268ecffee580d5",
      "8a2c75d53e55440c89d653a6d8aa5d53",
      "2d5e1f9270594eaaaa0d00d0ef805f51",
      "11cc8a99ef6d4c8f9d55725a18625d2e",
      "6a7809cea06140b59a9755bee33cc7d1",
      "fe7d95f424c34d44a2a309728bb0c724",
      "cc107184437a4ddda430849a60d8ba79",
      "baf5e9baf0f1464abefc47c7053379f0"
     ]
    },
    "id": "z-sE_0OlYqIY",
    "outputId": "cb275dcc-44a8-4ede-ceed-3c888cb83e7b"
   },
   "outputs": [],
   "source": [
    "for index, row in tq(df_all.iterrows()):\n",
    "  # Deteksi filepath\n",
    "  file_path = row['path']\n",
    "  if os.path.exists(file_path) == False:\n",
    "    file_path = os.path.join(datasource_path, row['labels'], row['iamge'].split('.')[0])\n",
    "\n",
    "  # buat direktori tujuan folder\n",
    "  if os.path.exists(os.path.join(dataset_path, row['set'], row['labels'])) == False:\n",
    "    os.makedirs(os.path.join(dataset_path, row['set'], row['labels']))\n",
    "\n",
    "  # tentukan tujuan file\n",
    "  destination_file_name = file_path.split('/')[-1]\n",
    "  file_dest = os.path.join(dataset_path, row['set'], row['labels'], destination_file_name)\n",
    "\n",
    "  # salin file dari sumber ke tujuan\n",
    "  if os.path.exists(file_dest) == False:\n",
    "    shutil.copy2(file_path, file_dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8DbGYPZZzRw"
   },
   "source": [
    "## Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUTGphnvefQB",
    "outputId": "459f8e25-b7a3-4c46-b80b-c6f0dfaa95ad"
   },
   "outputs": [],
   "source": [
    "# definisikan direktori\n",
    "TRAIN_DIR = 'Dataset-Final/train/'\n",
    "TEST_DIR = 'Dataset-Final/test/'\n",
    "VAL_DIR = 'Dataset-Final/val/'\n",
    "\n",
    "# Ambil semua nama kelas dari folder train\n",
    "classes = os.listdir(TRAIN_DIR)\n",
    "\n",
    "# Buat dictionary untuk menyimpan jumlah gambar per kelas\n",
    "train_counts = {}\n",
    "test_counts = {}\n",
    "val_counts = {}\n",
    "\n",
    "for cls in classes:\n",
    "    train_path = os.path.join(TRAIN_DIR, cls)\n",
    "    test_path = os.path.join(TEST_DIR, cls)\n",
    "    val_path = os.path.join(VAL_DIR, cls)\n",
    "\n",
    "    train_counts[cls] = len(os.listdir(train_path))\n",
    "    test_counts[cls] = len(os.listdir(test_path))\n",
    "    val_counts[cls] = len(os.listdir(val_path))\n",
    "\n",
    "\n",
    "# Tampilkan jumlah gambar per kelas\n",
    "print(\"Jumlah gambar pada dataset training:\")\n",
    "for cls, count in train_counts.items():\n",
    "    print(f\"{cls}: {count}\")\n",
    "\n",
    "print(\"\\nJumlah gambar pada dataset testing:\")\n",
    "for cls, count in test_counts.items():\n",
    "    print(f\"{cls}: {count}\")\n",
    "\n",
    "print(\"\\nJumlah gambar pada dataset validation:\")\n",
    "for cls, count in val_counts.items():\n",
    "    print(f\"{cls}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXdxNddjf4-Z",
    "outputId": "edd311a1-ce30-4bdd-efdc-3ffe3b243f7f"
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "# objek ImageDataGenerator yang menormalkan gambar\n",
    "datagen = ImageDataGenerator(rescale=1/255.,\n",
    "                             validation_split = 0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                              batch_size=32,\n",
    "                                              target_size=(224, 224),\n",
    "                                              color_mode='grayscale',\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(VAL_DIR,\n",
    "                                                   batch_size=32,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   color_mode='grayscale',\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                                  batch_size=1,\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nc-Ph-oIYAUU"
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQOZnNt8os1y"
   },
   "source": [
    "### Skema 1 - CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744
    },
    "id": "UTwK0t8XYAUU",
    "outputId": "602aebc8-1910-4ce6-a397-c612300578a2"
   },
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "# 1st\n",
    "model_1.add(Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(224, 224, 1)))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# 2nd\n",
    "model_1.add(Conv2D(32, (4, 4), padding='same', activation='relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# 3rd\n",
    "model_1.add(Conv2D(32, (7, 7), padding='same', activation='relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(128, activation='relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dropout(0.3))\n",
    "model_1.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# compiler\n",
    "model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0Z9CjdLid85",
    "outputId": "2ecf555c-ee1a-49a4-8888-7ebd57a27694"
   },
   "outputs": [],
   "source": [
    "# menghitung weight tiap kelas untuk mengatasi data yang imbalance\n",
    "\n",
    "# Ambil nama kelas\n",
    "classes = os.listdir(TRAIN_DIR)\n",
    "\n",
    "# Hitung jumlah gambar tiap kelas\n",
    "class_counts = {cls: len(os.listdir(os.path.join(TRAIN_DIR, cls))) for cls in classes}\n",
    "\n",
    "# Total semua data\n",
    "total = sum(class_counts.values())\n",
    "\n",
    "# Hitung class_weights\n",
    "class_weights = {\n",
    "    i: (1 / count) * (total / len(class_counts))\n",
    "    for i, (cls, count) in enumerate(class_counts.items())\n",
    "}\n",
    "\n",
    "# Buat mapping label kelas ke index (yang sesuai dengan class_indices dari ImageDataGenerator)\n",
    "class_indices = {cls: i for i, cls in enumerate(sorted(classes))}\n",
    "\n",
    "print(\"Class indices:\", class_indices)\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWgtK3YyjAqh",
    "outputId": "5c2070b4-34bf-4572-adc9-93f1e9a8cb24"
   },
   "outputs": [],
   "source": [
    "# callbacks\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Fitting / Training model\n",
    "history_1 = model_1.fit(train_generator,\n",
    "                        epochs=30,\n",
    "                        batch_size=32,\n",
    "                        validation_data=validation_generator,\n",
    "                        class_weight= class_weights,\n",
    "                        callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_hMiyv1x-RO"
   },
   "source": [
    "## Skema 2 - MobileNet v2 Transfer Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owvk-1vwyznB",
    "outputId": "862fe42c-b9ae-4082-8eb6-d22244a2fcf4"
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "# objek ImageDataGenerator yang menormalkan gambar\n",
    "datagen = ImageDataGenerator(rescale=1/255.,\n",
    "                             validation_split = 0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                              batch_size=32,\n",
    "                                              target_size=(224, 224),\n",
    "                                              color_mode='rgb',\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(VAL_DIR,\n",
    "                                                   batch_size=32,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   color_mode='rgb',\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                                  batch_size=1,\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  color_mode='rgb',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "2ApsEr6ox91G",
    "outputId": "38e09e5a-112d-4a86-e017-3fa8f98840c6"
   },
   "outputs": [],
   "source": [
    "# Initialize pre-trained MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "# Creating a new model\n",
    "model_2 = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(8, activation='softmax')  # 8 class\n",
    "])\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPs5GcZKyRMN",
    "outputId": "7f5a8372-5e3e-4d70-a284-388954dadb7d"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Training model_2\n",
    "history = model_2.fit(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[lr_scheduler, checkpoint, early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Model_2 evaluation on validation data\n",
    "val_loss, val_acc = model_2.evaluate(validation_generator)\n",
    "print(f'Validation accuracy: {val_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0OneTCS4lfp"
   },
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5m6gHpx2MMV",
    "outputId": "dda8ba7c-cec6-4ac0-ea84-f7f53cb7103b"
   },
   "outputs": [],
   "source": [
    "# Unfreeze some of the last layers of the base model\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Callbacks\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fine-tuning training\n",
    "history_fine_tune = model_2.fit(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[lr_scheduler, checkpoint, early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Model_2 evaluation on validation data\n",
    "val_loss, val_acc = model_2.evaluate(validation_generator)\n",
    "print(f'Validation accuracy: {val_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XctzCfzbYCBK"
   },
   "source": [
    "## Evaluasi dan Visualisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894
    },
    "id": "EKk-ScZWYCBK",
    "outputId": "2a69f3b3-4d2a-47cf-ae8e-e406893200fd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Reset generator agar prediksi dimulai dari awal\n",
    "test_generator.reset()\n",
    "\n",
    "# prediksi model\n",
    "preds_1 = model_2.predict(test_generator, verbose=0)\n",
    "\n",
    "# Ambil prediksi kelas\n",
    "predicted_classes = np.argmax(preds_1, axis=1)\n",
    "\n",
    "# Label ground truth dari generator\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Nama kelas (harus sesuai urutan class_indices dari generator)\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Print Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "cm_df = pd.DataFrame(cm, index=class_labels, columns=[f'Predicted {label}' for label in class_labels])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.show()\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "SX7bdSG1vVe3",
    "outputId": "c16c5814-ab58-480b-ec17-1c0fb340b404"
   },
   "outputs": [],
   "source": [
    "acc = history_fine_tune.history['accuracy']\n",
    "val_acc = history_fine_tune.history['val_accuracy']\n",
    "loss = history_fine_tune.history['loss']\n",
    "val_loss = history_fine_tune.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.title('Training and Validaion Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_fIsUogYFSk"
   },
   "source": [
    "## Konversi Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgKo7VB5HApC"
   },
   "source": [
    "### SaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZvGBpYoYFSl"
   },
   "outputs": [],
   "source": [
    "save_path = 'mymodel/'\n",
    "tf.saved_model.save(model_2, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmUScaJPHDgi"
   },
   "source": [
    "###Format tf.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJoTQSyTHhQS",
    "outputId": "b38a2da8-0dfd-47ef-df33-1bc3149a95b5"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jjEe9KyHGti",
    "outputId": "32ea9cf8-f11e-4778-b597-b9ef2e15da3b"
   },
   "outputs": [],
   "source": [
    "!tensorflowjs_converter \\\n",
    "    --input_format=tf_saved_model \\\n",
    "    /content/mymodel/ \\\n",
    "    /content/modeltfjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dwRvDeIHQYj"
   },
   "source": [
    "### Format tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKFpUTM9HTYb"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"mymodel\")\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with tf.io.gfile.GFile('tomato_disease.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUe1zjNCtTnP",
    "outputId": "b2cfc010-877f-42ba-be6a-7e64ae650566"
   },
   "outputs": [],
   "source": [
    "model_2.save(\"tanamind_tomato.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "1oITZDFztnd-",
    "outputId": "f6652307-7efc-473e-86bc-7e74633b14f9"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('tanamind_tomato.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DbfEwvvm5U4"
   },
   "source": [
    "## Inference (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "ue5esMSSm8GQ",
    "outputId": "c46e6ba0-3db6-4500-fe3d-7738e559841d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Ambil probabilitas prediksi dari model\n",
    "probabilities = model_2.predict(test_generator, verbose=1)\n",
    "\n",
    "# Ambil label kelas dari generator\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Pilih 5 gambar acak dari dataset\n",
    "random_indices = random.sample(range(len(test_generator.filenames)), 5)\n",
    "\n",
    "# Atur layout gambar dalam 1 baris\n",
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "for i, index in enumerate(random_indices):\n",
    "    probability = probabilities[index]\n",
    "    image_path = os.path.join(TEST_DIR, test_generator.filenames[index])\n",
    "    img = mpimg.imread(image_path)\n",
    "\n",
    "    # Prediksi dan ambil label dengan probabilitas tertinggi\n",
    "    predicted_class_index = np.argmax(probability)\n",
    "    confidence = probability[predicted_class_index] * 100\n",
    "    predicted_label = class_labels[predicted_class_index]\n",
    "\n",
    "    # Tampilkan gambar dengan judul prediksi\n",
    "    plt.subplot(1, 5, i+1)  # 1 baris, 5 kolom, gambar ke-i\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Matikan axis\n",
    "    plt.title(f\"{predicted_label}\\n{confidence:.2f}%\")\n",
    "\n",
    "plt.tight_layout()  # Mengatur layout agar gambar tidak bertumpuk\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "rDdJLtrPKeoj",
    "outputId": "85bc45f6-e6b1-4887-fffc-bc774e3fc300"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Ganti dengan path file gambar lokal\n",
    "image_path = 'test.jpg'\n",
    "\n",
    "# Load dan praproses gambar\n",
    "img = image.load_img(image_path, target_size=(150, 150))  # sesuaikan ukuran input model\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # tambah dimensi batch\n",
    "img_array = img_array / 255.0  # normalisasi jika diperlukan\n",
    "\n",
    "# Lakukan prediksi\n",
    "prediction = model_2.predict(img_array)\n",
    "\n",
    "# Ambil label kelas\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Dapatkan hasil prediksi\n",
    "predicted_index = np.argmax(prediction[0])\n",
    "predicted_label = class_labels[predicted_index]\n",
    "confidence = prediction[0][predicted_index] * 100\n",
    "\n",
    "# Tampilkan gambar dan hasil prediksi\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(f\"{predicted_label}\\n{confidence:.2f}%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "JpzEc0OpL9NE",
    "outputId": "5f949219-3d7b-4455-dc9d-2403c93993a8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Ganti dengan path file gambar lokal\n",
    "image_path = 'sehat.jpg'\n",
    "\n",
    "# Load dan praproses gambar\n",
    "img = image.load_img(image_path, target_size=(150, 150))  # sesuaikan ukuran input model\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # tambah dimensi batch\n",
    "img_array = img_array / 255.0  # normalisasi jika diperlukan\n",
    "\n",
    "# Lakukan prediksi\n",
    "prediction = model_2.predict(img_array)\n",
    "\n",
    "# Ambil label kelas\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Dapatkan hasil prediksi\n",
    "predicted_index = np.argmax(prediction[0])\n",
    "predicted_label = class_labels[predicted_index]\n",
    "confidence = prediction[0][predicted_index] * 100\n",
    "\n",
    "# Tampilkan gambar dan hasil prediksi\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(f\"{predicted_label}\\n{confidence:.2f}%\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
